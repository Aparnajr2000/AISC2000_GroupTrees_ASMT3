{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">AISC2000 - Group Trees - Assignment 3 Task Distribution and Status</h1>\n",
        "\n",
        "| Individual Responsible | Task | Status | Results |\n",
        "|:---|:---|:---|:---|\n",
        "| **SUBHASH PAVAN CHAKRAVARTHY SOMAROUTHU** | Data Preprocessing and Feature Engineering | Class Separability Checked? Train and Test Handled Correctly? | Featureset with best separability? Steps taken before and after train test split? |\n",
        "|  | Feature Importance Analysis (Random Forests) | Implemented? Compared with LIME/SHAP? | Key findings from comparison |\n",
        "|  | Check feature importance using Random Forests | Implemented? | Key findings |\n",
        "| **KANIKA** | Data Visualization for Feature Engineering | Visualizations created before model training? | Insights from visualizations |\n",
        "|  | Next Steps Analysis | List out 2-3 possible next steps for each model |  |\n",
        "|  | Summarize understanding of outputs from feature importance and tuning | Summary completed? | Key insights |\n",
        "|  | Final Report Compilation | Compile all sections, ensure HTML export of Jupyter notebook |  |\n",
        "| **GOKUL KRISHNA POURNAMI GOPI** | SVM Model (Count-Vectors with Unigram) | Config of model trained? Train Time? | Ensure >5000 data points in test set |\n",
        "|  | SVM Model (TF-IDF with Unigram+Bigram) | Config of model trained? Train Time? | Ensure >5000 data points in test set |\n",
        "|  | Model Evaluation (All Models) | Confusion Matrix Built? AUC plotted? Accuracy computed? | F1 Score for Positive/Negative, AUC, Accuracy |\n",
        "|  | Run 3 rounds of empirical tuning on SVM models | Tuning completed? | Performance improvements |\n",
        "| **APARNA JAYAKUMAR RESMI** | Random Forest Model (Parking Identification) | Config of the model trained? Train Time? | Ensure >5000 data points in test set |\n",
        "|  | Random Forest Model (Parking Validation) | Config of the model trained? Train Time? | Ensure >5000 data points in test set |\n",
        "|  | Run 3 rounds of empirical tuning on Random Forest models | Tuning completed? | Performance improvements |\n",
        "| **CLIFFORD ADDISON** | XGBoost Model (Parking Identification) | Config of model trained? Train Time? | Ensure >5000 data points in test set |\n",
        "|  | XGBoost Model (Parking Validation) | Config of model trained? Train Time? | Ensure >5000 data points in test set |\n",
        "|  | Run 3 rounds of empirical tuning on XGBoost models | Tuning completed? | Performance improvements |\n",
        "| **OBIANUJU NONYEREM ANUMA** | 1 Hidden Layer ANN (Parking Identification) | Config of model trained? Train Time? | Ensure >5000 data points in test set |\n",
        "|  | 1 Hidden Layer ANN (Parking Validation) | Config of model trained? Train Time? | Ensure >5000 data points in test set |\n",
        "|  | Run 3 rounds of empirical tuning on ANN models | Tuning completed? | Performance improvements |\n",
        "| **ABDULLAH IFTEQAR MOHAMMED** | Multi-Hidden Layer ANN (Parking Identification) | Config of model trained? Train Time? Use dropout, regularization, early stopping, and weight initialization. |\n",
        "|  | Multi-Hidden Layer ANN (Parking Validation) | Config of model trained? Train Time? Use dropout, regularization, early stopping, and weight initialization. |\n",
        "|  | Run 3 rounds of empirical tuning on Multi-Hidden Layer ANN models | Tuning completed? | Performance improvements |\n",
        "| **MUKUL GARG** | Naive Bayes Model (One-Hot Vectors for Unigram+Bigram) | Config of model trained? Train Time? Ensure >5000 data points in test set. |\n",
        "|  | Interpretability Analysis (All Models) | Interpretability Implemented? Local or Global? 2 interesting findings per model. |\n",
        "|  | Run 3 rounds of empirical tuning on Naive Bayes model | Tuning completed? | Performance improvements |\n",
        "|  | Cross Validation (All Models) | Type of Cross Validation performed? Findings of Cross Validation? |  |\n",
        "| **AMRUTH RAJ MANCHIKANTI** | SVM Model using word2vec (CBOW or Skipgram)  | Config of model trained? Vector size (64-300)? Train Time? Use CBOW or Skipgram. |\n",
        "|  | SVM Model using other word embedding (GloVe, Fasttext, or ELMo)  | Config of model trained? Embedding type chosen?| Train Time?| Ensure >5000 data points in test set. |\n",
        "|  | Run 3 rounds of empirical tuning on word embedding SVM models | Tuning completed? | Performance improvements |\n",
        "| **SANGEETH KUMARASINGHE** | LIME Analysis for All Models | LIME implemented for each model? | Key local interpretability findings |\n",
        "|  | SHAP Analysis for All Models | SHAP values calculated for each model? | Global and local interpretability insights |\n",
        "|  | Compare LIME and SHAP results | Comparison completed? | Key differences and similarities between LIME and SHAP interpretations |\n",
        "\n",
        "## Individual Responsibilities for All Team Members\n",
        "- Contribute to empirical tuning (3 rounds for your assigned models) and derive insights from each iteration.\n",
        "- Review and validate results for your assigned models.\n",
        "- Explain tuning approaches used in each iteration for your models.\n",
        "- Call out what else could be done to tune your models and how it would have helped (with numbers) at the top/bottom of your section in the notebook.\n",
        "- Ensure >5000 data points in the test set for your models' Confusion Matrix, AUC, etc.\n",
        "- Submit your part of the Python notebook to be run sequentially end to end and exported as an HTML file"
      ],
      "metadata": {
        "id": "UYoSBW7swzNz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zfg5gIZwxha"
      },
      "outputs": [],
      "source": []
    }
  ]
}